{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FacialLandmarks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waidhoferj/CSC-566-Project/blob/frame-loader/FacialLandmarks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJZwDvM21EV"
      },
      "source": [
        "# Facial Landmarks\n",
        "Experimentation with facial landmarks models and datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFjoPKY-ZaY",
        "outputId": "a20d45ce-3ccf-42c6-9a0b-0a910a8a9aa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "import random\n",
        "!pip install mtcnn\n",
        "from mtcnn import MTCNN\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCIThEi--w0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb2d1db-b5f3-4f9a-f28c-d44061f5ff71"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXe9WUnF2_O3"
      },
      "source": [
        "Add your name and filepath to the project folder so that you can load the datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngxIBPhm1Q80"
      },
      "source": [
        "USER = \"John\"\n",
        "USER_FILEPATHS = {\n",
        "    \"John\" : \"/content/drive/MyDrive/CSC 566 Project\",\n",
        "    \"Jeremy\" : \"/content/drive/MyDrive/School/Undergrad/2021 Spring/CSC 566/CSC 566 Project\",\n",
        "    \"Ty\" : \"/content/drive/MyDrive/CSC 566 Project\"\n",
        "}\n",
        "PROJECT_FILEPATH = USER_FILEPATHS[USER]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpSQj0yh2UTF"
      },
      "source": [
        "# Sanity check for loading data\n",
        "def display_landmarks(img, points):\n",
        "  \"\"\"\n",
        "  Displays portrait with landmark dots drawn on the face.\n",
        "  Assumes that points are in (68,2)\n",
        "  \"\"\"\n",
        "  #If we are reading from .mat files directly (2,68)\n",
        "  if points.shape[0] == 2:\n",
        "    points = points.transpose(1,0)\n",
        "  #If reading from model output\n",
        "  elif len(points.shape) == 1:\n",
        "    points = points.reshape(-1,2)\n",
        "  fig,ax = plt.subplots(1)\n",
        "  ax.set_aspect('equal')\n",
        "  ax.imshow(img)\n",
        "  for p in points:\n",
        "      circ = Circle(p)\n",
        "      ax.add_patch(circ)\n",
        "  plt.show()\n",
        "\n",
        "#points = loadmat(AFW_DATASET + \"/70037463_1.mat\")[\"pt2d\"]\n",
        "#img  = plt.imread( AFW_DATASET+\"/70037463_1.jpg\")\n",
        "\n",
        "#display_landmarks(img,points)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ux1miy3D0oD"
      },
      "source": [
        "path = os.path.join(PROJECT_FILEPATH, \"webCamData\", \"inputVideo.mp4\")\n",
        "vcap = cv2.VideoCapture(path)\n",
        "\n",
        "success = 1\n",
        "i = 0\n",
        "frames = []\n",
        "image_shape = (vcap.get(4), vcap.get(3), 3)\n",
        "\n",
        "while success and i < 50:\n",
        "  success, frame = vcap.read()\n",
        "  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "  frames.append(frame)\n",
        "  i+=1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2TwJdAO1bB1",
        "outputId": "de131caa-5695-4c95-be9a-373c85812d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "mtcnn = MTCNN()\n",
        "cropped_frames = []\n",
        "for i, frame in enumerate(frames):\n",
        "  print(f\"\\r{i}\",end=\"\")\n",
        "  faces = mtcnn.detect_faces(frame)\n",
        "  if len(faces) > 0:\n",
        "    x,y,w,h = faces[0][\"box\"]\n",
        "    cropped_frames.append(frame[x:x+w, y:y+h])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQc5qiW1FzcD"
      },
      "source": [
        "def relu6(x):\n",
        "  return tf.clip_by_value(x, 0, 6)\n",
        "\n",
        "model_path = os.path.join(PROJECT_FILEPATH, \"models\", \"PFLD.h5\")\n",
        "model = tf.keras.models.load_model(model_path, custom_objects={\"relu6\": relu6})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr31eAIQVGlu"
      },
      "source": [
        "### Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQDXEAI7Ol6N"
      },
      "source": [
        "input_data[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQJxDEObVSOx"
      },
      "source": [
        "input_data = [tf.image.resize(frame, (450,450)).numpy().astype(\"uint8\") for frame in cropped_frames]\n",
        "norm_points, angles = model.predict(np.array(input_data))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9V-u_aUPmaS"
      },
      "source": [
        "input_data[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AShlJ00Vz81"
      },
      "source": [
        "#@title View Predicted Images\n",
        "image_index = 5 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "points = norm_points * 450\n",
        "\n",
        "i = 0\n",
        "for frame in input_data:\n",
        "  if (i == image_index):\n",
        "    display_landmarks(frame, points[image_index])\n",
        "    break\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odgsbWZDIwk8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}